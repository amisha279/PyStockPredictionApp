{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:17:57.066196500Z",
     "start_time": "2026-02-13T15:17:57.048724300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "69c0d16b362d2949",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:17:57.093707400Z",
     "start_time": "2026-02-13T15:17:57.068197900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. CONFIG\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "TICKERS = [\n",
    "    \"AAPL\", \"TSLA\", \"MSFT\", \"GOOGL\", \"META\",\n",
    "    \"NVDA\", \"AMZN\", \"NFLX\", \"AMD\", \"INTC\",\n",
    "    \"ETH\", \"BTC\", \"Gold\", \"Silver\", \"RGTI\",\n",
    "    \"COST\", \"MU\", \"GOOG\", \"BTC\", \"DJI\", \"INX\",\n",
    "    \"T\", \"ONDS\"\n",
    "\n",
    "]\n",
    "\n",
    "YEARS = \"5y\"   # how much history to download\n",
    "INTERVAL = \"1d\""
   ],
   "id": "acd424e78dcccd7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:17:57.135907200Z",
     "start_time": "2026-02-13T15:17:57.103708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def build_features(df):\n",
    "    df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "    df[\"MA5\"] = df[\"Close\"].rolling(5).mean()\n",
    "    df[\"MA20\"] = df[\"Close\"].rolling(20).mean()\n",
    "    df[\"Volatility\"] = df[\"Return\"].rolling(10).std()\n",
    "    df[\"NextClose\"] = df[\"Close\"].shift(-1)\n",
    "    return df.dropna()"
   ],
   "id": "90f851a63209f31c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:01.068753700Z",
     "start_time": "2026-02-13T15:17:57.137992300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. BUILD MULTI-STOCK DATASET\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    print(f\"Downloading {ticker}...\")\n",
    "    df = yf.download(ticker, period=YEARS, interval=INTERVAL)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"⚠️ No data for {ticker}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    df = build_features(df)\n",
    "    df[\"Ticker\"] = ticker\n",
    "    all_data.append(df)\n",
    "\n",
    "dataset = pd.concat(all_data)\n",
    "dataset = dataset.dropna()"
   ],
   "id": "c628325bccb4b073",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TSLA...\n",
      "Downloading MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GOOGL...\n",
      "Downloading META...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NVDA...\n",
      "Downloading AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NFLX...\n",
      "Downloading AMD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading INTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ETH...\n",
      "Downloading BTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gold...\n",
      "Downloading Silver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: SILVER\"}}}\n",
      "$SILVER: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SILVER']: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data for Silver, skipping.\n",
      "Downloading RGTI...\n",
      "Downloading COST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GOOG...\n",
      "Downloading BTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "$INX: possibly delisted; no price data found  (period=5y)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['INX']: possibly delisted; no price data found  (period=5y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading DJI...\n",
      "Downloading INX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data for INX, skipping.\n",
      "Downloading T...\n",
      "Downloading ONDS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:01.102987Z",
     "start_time": "2026-02-13T15:18:01.078860600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. ENCODE TICKER AS CATEGORY\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "dataset[\"Ticker\"] = dataset[\"Ticker\"].astype(\"category\")\n",
    "dataset[\"TickerCode\"] = dataset[\"Ticker\"].cat.codes"
   ],
   "id": "71b7d4eeb9f4e2fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amish\\AppData\\Local\\Temp\\ipykernel_25760\\2791048980.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset[\"TickerCode\"] = dataset[\"Ticker\"].cat.codes\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:01.132069500Z",
     "start_time": "2026-02-13T15:18:01.113002700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 5. SELECT FEATURES\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "feature_cols = [\n",
    "    \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"MA5\", \"MA20\", \"Volatility\" ]\n",
    "    #\"MA5\", \"MA20\", \"Volatility\", \"TickerCode\"\n",
    "\n",
    "X = dataset[feature_cols]\n",
    "y = dataset[\"NextClose\"]"
   ],
   "id": "d45d30fa69b835ef",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:01.151441Z",
     "start_time": "2026-02-13T15:18:01.133070900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"Target\"] = df[\"Close\"].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"MA5\", \"MA20\", \"Volatility\"]]\n",
    "y = df[\"Target\"]"
   ],
   "id": "412c5bb94c1a3598",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:01.585512500Z",
     "start_time": "2026-02-13T15:18:01.153439300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 6. TRAIN MODEL\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print(\"Training model...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Model R² Score: {score:.4f}\")"
   ],
   "id": "31c86624811c6a62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Model R² Score: 0.9874\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:01.612165700Z",
     "start_time": "2026-02-13T15:18:01.586509200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Head X:\\n\", X.head())\n",
    "print(\"Head y:\\n\", y.head())"
   ],
   "id": "7fbe842950d0fc07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1235, 8)\n",
      "y shape: (1235,)\n",
      "Head X:\n",
      " Price        Open   High    Low  Close  Volume     MA5     MA20 Volatility\n",
      "Ticker       ONDS   ONDS   ONDS   ONDS    ONDS                            \n",
      "Date                                                                      \n",
      "2021-03-15  11.00  11.85  10.80  11.75  294500  10.808  12.1680   0.096599\n",
      "2021-03-16  11.91  12.15  11.08  11.29  306100  11.084  11.9625   0.096130\n",
      "2021-03-17  11.06  11.90  11.06  11.80  331200  11.426  11.8860   0.097386\n",
      "2021-03-18  11.56  12.25  11.21  11.26  335800  11.418  11.8150   0.091390\n",
      "2021-03-19  11.51  12.24  11.09  11.32  880600  11.484  11.7675   0.086466\n",
      "Head y:\n",
      " Date\n",
      "2021-03-15    11.29\n",
      "2021-03-16    11.80\n",
      "2021-03-17    11.26\n",
      "2021-03-18    11.32\n",
      "2021-03-19    11.70\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:01.719987600Z",
     "start_time": "2026-02-13T15:18:01.622182Z"
    }
   },
   "source": [
    "# ---------------------------------------------------------\n",
    "# 7. SAVE MODEL + FEATURE COLUMNS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "joblib.dump(model, \"stock_model.pkl\")\n",
    "joblib.dump(feature_cols, \"feature_columns.pkl\")\n",
    "joblib.dump(dataset[\"Ticker\"].cat.categories.tolist(), \"ticker_categories.pkl\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - stock_model.pkl\")\n",
    "print(\" - feature_columns.pkl\")\n",
    "print(\" - ticker_categories.pkl\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - stock_model.pkl\n",
      " - feature_columns.pkl\n",
      " - ticker_categories.pkl\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:14.318186700Z",
     "start_time": "2026-02-13T15:18:01.720987800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TICKERS = [\n",
    "    \"AAPL\", \"TSLA\", \"MSFT\", \"GOOGL\", \"META\",\n",
    "    \"NVDA\", \"AMZN\", \"NFLX\", \"AMD\", \"INTC\",\n",
    "    \"ETH\", \"BTC\", \"Gold\", \"Silver\", \"RGTI\",\n",
    "    \"COST\", \"MU\", \"GOOG\", \"BTC\", \"DJI\", \"INX\",\n",
    "    \"T\", \"ONDS\"\n",
    "\n",
    "]\n",
    "\n",
    "YEARS = \"5y\"\n",
    "INTERVAL = \"1d\"\n",
    "\n",
    "def build_features(df):\n",
    "    df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "    df[\"MA5\"] = df[\"Close\"].rolling(5).mean()\n",
    "    df[\"MA20\"] = df[\"Close\"].rolling(20).mean()\n",
    "    df[\"Volatility\"] = df[\"Return\"].rolling(10).std()\n",
    "    df[\"NextClose\"] = df[\"Close\"].shift(-1)\n",
    "    return df.dropna()\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    print(f\"Downloading {ticker}...\")\n",
    "    df = yf.download(ticker, period=YEARS, interval=INTERVAL)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"⚠️ No data for {ticker}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # FIX: flatten MultiIndex columns\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "    df = build_features(df)\n",
    "    df[\"Ticker\"] = ticker\n",
    "    all_data.append(df)\n",
    "\n",
    "dataset = pd.concat(all_data)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "dataset[\"Ticker\"] = dataset[\"Ticker\"].astype(\"category\")\n",
    "dataset[\"TickerCode\"] = dataset[\"Ticker\"].cat.codes\n",
    "\n",
    "feature_cols = [\n",
    "    \"Open\", \"High\", \"Low\", \"Close\", \"Volume\",\n",
    "    \"MA5\", \"MA20\", \"Volatility\", \"TickerCode\"\n",
    "]\n",
    "\n",
    "X = dataset[feature_cols]\n",
    "y = dataset[\"NextClose\"]\n",
    "\n",
    "print(\"Training model...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Model R² Score: {score:.4f}\")\n",
    "\n",
    "joblib.dump(model, \"stock_model.pkl\")\n",
    "joblib.dump(feature_cols, \"feature_columns.pkl\")\n",
    "joblib.dump(dataset[\"Ticker\"].cat.categories.tolist(), \"ticker_categories.pkl\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - stock_model.pkl\")\n",
    "print(\" - feature_columns.pkl\")\n",
    "print(\" - ticker_categories.pkl\")"
   ],
   "id": "c5b18d72ca711a2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GOOGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading META...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NFLX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AMD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading INTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ETH...\n",
      "Downloading BTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gold...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "$SILVER: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Silver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['SILVER']: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data for Silver, skipping.\n",
      "Downloading RGTI...\n",
      "Downloading COST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MU...\n",
      "Downloading GOOG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading BTC...\n",
      "Downloading DJI...\n",
      "Downloading INX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$INX: possibly delisted; no price data found  (period=5y)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['INX']: possibly delisted; no price data found  (period=5y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data for INX, skipping.\n",
      "Downloading T...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ONDS...\n",
      "Training model...\n",
      "Model R² Score: 0.9999\n",
      "Saved:\n",
      " - stock_model.pkl\n",
      " - feature_columns.pkl\n",
      " - ticker_categories.pkl\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 60 days ahead prediction",
   "id": "ce4dd7d160612555"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:14.334175800Z",
     "start_time": "2026-02-13T15:18:14.319188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "SEQ_LEN = 60   # past 60 days\n",
    "HORIZON = 60   # predict 60 days ahead\n",
    "\n",
    "def build_sequences(df, feature_cols, target_col=\"Close\"):\n",
    "    data = df[feature_cols].values\n",
    "    target = df[target_col].values\n",
    "\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(df) - SEQ_LEN - HORIZON + 1):\n",
    "        X_seq.append(data[i:i+SEQ_LEN])\n",
    "        y_seq.append(target[i+SEQ_LEN:i+SEQ_LEN+HORIZON])  # 60-step future\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ],
   "id": "6f879df2a135483f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:18:14.417338700Z",
     "start_time": "2026-02-13T15:18:14.337177900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_cols = [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"MA5\",\"MA20\",\"Volatility\"]\n",
    "X_seq, y_seq = build_sequences(dataset, feature_cols, target_col=\"Close\")"
   ],
   "id": "b7f7abcb81086614",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full LSTM model (PyTorch, 60‑day path)",
   "id": "8aa8b0b344910130"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:21:06.837726100Z",
     "start_time": "2026-02-13T15:18:14.419337900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, horizon=60):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)          # (B, T, H)\n",
    "        last = out[:, -1, :]           # (B, H)\n",
    "        return self.fc(last)           # (B, horizon)\n",
    "\n",
    "X_t = torch.tensor(X_seq, dtype=torch.float32)\n",
    "y_t = torch.tensor(y_seq, dtype=torch.float32)\n",
    "\n",
    "ds = TensorDataset(X_t, y_t)\n",
    "dl = DataLoader(ds, batch_size=64, shuffle=True)\n",
    "\n",
    "model = LSTMForecaster(input_dim=len(feature_cols))\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    for xb, yb in dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()"
   ],
   "id": "77666a0b058d02e2",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformer model (PyTorch, 60‑day path)",
   "id": "38ca0b5d87bc4621"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerForecaster(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2, horizon=60):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)         # (B, T, d_model)\n",
    "        enc = self.encoder(x)          # (B, T, d_model)\n",
    "        last = enc[:, -1, :]           # (B, d_model)\n",
    "        return self.fc(last)           # (B, horizon)\n",
    "\n",
    "model = TransformerForecaster(input_dim=len(feature_cols))\n",
    "# same training loop as LSTM (just swap model)"
   ],
   "id": "927f169843bb3d84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Recursive Random Forest (using your existing RF)",
   "id": "646464cf78a5c2ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rf_recursive_forecast(model, df, feature_cols, steps=60):\n",
    "    df = df.copy()\n",
    "    preds = []\n",
    "    for _ in range(steps):\n",
    "        X_latest = df[feature_cols].iloc[-1:].values\n",
    "        next_close = model.predict(X_latest)[0]\n",
    "        preds.append(next_close)\n",
    "\n",
    "        # append synthetic next row\n",
    "        new_row = df.iloc[-1].copy()\n",
    "        new_row[\"Close\"] = next_close\n",
    "        # recompute features that depend on Close\n",
    "        df = pd.concat([df, new_row.to_frame().T])\n",
    "        df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "        df[\"MA5\"] = df[\"Close\"].rolling(5).mean()\n",
    "        df[\"MA20\"] = df[\"Close\"].rolling(20).mean()\n",
    "        df[\"Volatility\"] = df[\"Return\"].rolling(10).std()\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    return preds"
   ],
   "id": "572e86ed21ca5d5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hybrid model (RF + LSTM)\n",
    "One simple, effective hybrid:\n",
    "- RF predicts the 60‑day‑ahead level (single value).\n",
    "- LSTM predicts the shape (normalized path).\n",
    "- You scale the LSTM path to land at the RF target.\n"
   ],
   "id": "d90bbfccada96161"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# RF: train on Target60 = Close.shift(-60)\n",
    "# LSTM: train on normalized 60-day future: (future / future[0]) - 1\n",
    "\n",
    "def combine_hybrid(rf_price_60, lstm_path_60, last_close):\n",
    "    # lstm_path_60: relative path, e.g. returns or normalized\n",
    "    # simple version: scale so last point matches rf_price_60\n",
    "    raw_path = lstm_path_60  # e.g. absolute prices from LSTM\n",
    "    scale = rf_price_60 / raw_path[-1]\n",
    "    return raw_path * scale"
   ],
   "id": "f33c512ee92b38f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full Hybrid Function",
   "id": "681e4c217ee6ec14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def hybrid_align(rf_target_60, lstm_path_60):\n",
    "    \"\"\"\n",
    "    rf_target_60: scalar (RF prediction for day +60)\n",
    "    lstm_path_60: array of shape (60,) with LSTM predicted prices\n",
    "    \"\"\"\n",
    "    final_lstm = lstm_path_60[-1]\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if final_lstm == 0:\n",
    "        return lstm_path_60\n",
    "\n",
    "    scale = rf_target_60 / final_lstm\n",
    "    hybrid_path = lstm_path_60 * scale\n",
    "\n",
    "    # alpha = np.linspace(0.0, 1.0, 60)  # gradually shift weight to RF\n",
    "    # hybrid_path = (1 - alpha) * lstm_path_60 + alpha * (lstm_path_60 * scale)\n",
    "    return hybrid_path"
   ],
   "id": "881c037af6b74cb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The hybrid alignment function (final point forced to RF target)",
   "id": "f6e42618e829d458"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def hybrid_align(rf_target_60, lstm_path_60):\n",
    "    \"\"\"\n",
    "    rf_target_60: scalar predicted by RF for day +60\n",
    "    lstm_path_60: array of shape (60,) predicted by LSTM/Transformer\n",
    "    \"\"\"\n",
    "    final_lstm = lstm_path_60[-1]\n",
    "\n",
    "    if final_lstm == 0:\n",
    "        return lstm_path_60\n",
    "\n",
    "    scale = rf_target_60 / final_lstm\n",
    "    hybrid_path = lstm_path_60 * scale\n",
    "    return hybrid_path"
   ],
   "id": "bcf11a818db031ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Your Flask /predict route with hybrid forecasting\n",
    "This version assumes:\n",
    "- model_rf is your RandomForestRegressor trained on Target60\n",
    "- model_lstm is your LSTM model predicting a 60‑day path\n",
    "- build_features(df) is unchanged\n",
    "- feature_cols is the same 8‑feature list you trained on\n",
    "\n",
    "````\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    ticker = data.get(\"ticker\", \"\").upper()\n",
    "\n",
    "    try:\n",
    "        df = yf.download(ticker, period=\"120d\", interval=\"1d\")\n",
    "\n",
    "        if df.empty:\n",
    "            return jsonify({\"reply\": f\"No data found for {ticker}\"}), 400\n",
    "\n",
    "        # Flatten MultiIndex\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "        df = build_features(df)\n",
    "\n",
    "        if df.empty or len(df) < 60:\n",
    "            return jsonify({\"reply\": f\"Not enough data for {ticker}\"}), 400\n",
    "\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # --- 1. RF 60-day prediction ---\n",
    "        X_latest = df[feature_cols].iloc[-1:].values\n",
    "        rf_target_60 = float(model_rf.predict(X_latest)[0])\n",
    "\n",
    "        # --- 2. LSTM 60-day path prediction ---\n",
    "        seq = df[feature_cols].values[-60:]\n",
    "        seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            lstm_path_60 = model_lstm(seq).numpy()[0]\n",
    "\n",
    "        # --- 3. Hybrid alignment ---\n",
    "        hybrid_path = hybrid_align(rf_target_60, lstm_path_60)\n",
    "\n",
    "        # Build dates for the next 60 days\n",
    "        last_date = df.index[-1]\n",
    "        future_dates = [(last_date + pd.Timedelta(days=i+1)).strftime(\"%Y-%m-%d\") for i in range(60)]\n",
    "\n",
    "        return jsonify({\n",
    "            \"reply\": f\"60-day forecast for {ticker}\",\n",
    "            \"ticker\": ticker,\n",
    "            \"future_dates\": future_dates,\n",
    "            \"hybrid_forecast\": hybrid_path.tolist(),\n",
    "            \"rf_target_60\": rf_target_60,\n",
    "            \"lstm_raw_path\": lstm_path_60.tolist()\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"ERROR IN /predict ROUTE:\")\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"reply\": f\"Error: {str(e)}\"}), 500\n",
    "````\n"
   ],
   "id": "afe60b334be7c2bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ffee17730279def6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
